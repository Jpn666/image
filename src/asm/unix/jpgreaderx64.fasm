;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; Copyright (C) 2021, jpn 
; 
; Licensed under the Apache License, Version 2.0 (the "License");
; you may not use this file except in compliance with the License.
; You may obtain a copy of the License at
; 
; http://www.apache.org/licenses/LICENSE-2.0
; 
; Unless required by applicable law or agreed to in writing, software
; distributed under the License is distributed on an "AS IS" BASIS,
; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
; See the License for the specific language governing permissions and
; limitations under the License.
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

format ELF64

; for better column aligment
xmmA equ xmm10
xmmB equ xmm11
xmmC equ xmm12
xmmD equ xmm13
xmmE equ xmm14
xmmF equ xmm15


section '.text' executable align 16


public jpgr_inverseDCT
; Parameters:
; (int16 pointer) sblock , rblock, qtable

public jpgr_setrow1
; Parameters:
; (pointer) int16 row source, (pointer) int8 target

public jpgr_setrow3
; Parameters:
; (pointer) int16 row1, row2, row2, (pointer) int8 target, int transform


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; Initialize the jump table according to the CPU capabilities
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

SSSE3_FLAG = 0000200h


initjump:
	; preserve registers
	push		rcx
	push		rdx
	push		rbx
    
	xor			rax, rax
	cmp			rax, qword[initdone]
	jne .done
    
	mov			eax, 1
	cpuid
	and			ecx, SSSE3_FLAG

	; sse2
	lea			rax, [sse2_setrow3]
	mov			qword[jumptable.setrow3], rax
	test		ecx, ecx
	jz .done
    
	; ssse3
	lea			rax, [ssse3_setrow3]
	mov			qword[jumptable.setrow3], rax

.done:
	lea			rax, [initdone]
	mov			qword[rax], 1h

	pop			rbx
	pop			rdx
	pop			rcx
	jmp qword[jumptable.setrow3]


jpgr_setrow1:
	jmp sse2_setrow1

jpgr_setrow3:
	jmp qword[jumptable.setrow3]


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; SSE2 version
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

align 16
c128:
	dw 8 dup (128)

; rdi=r1, rsi=destination
sse2_setrow1:
	movdqa      xmm0, [rdi]
	paddw       xmm0, [c128]
	packuswb    xmm0, xmm0
	movq        [rsi], xmm0
	
	ret


; Constants
fixed_1_402 equ 5743
fixed_0_344 equ 1410
fixed_0_714 equ 2925
fixed_1_772 equ 7258

align 16
c1: dw 4 dup (        4096,  fixed_1_402)
c2: dw 4 dup (-fixed_0_344, -fixed_0_714)
c3: dw 4 dup (        4096,  fixed_1_772)
c4: dd 8 dup (526336)

; rdi=r1, rsi=r2, rdx=r3, rcx=destination, r8=transform
sse2_setrow3:
	movdqa      xmm1, [rdi]
	movdqa      xmm2, [rsi]
	movdqa      xmm3, [rdx]

	cmp			r8, 0h
	je .notransform

	; r = y + cr * 1.402
	; implemented as 
	; y * scale + cr * 1.402
	movdqa		xmm4, xmm1
	movdqa		xmm5, xmm1
	punpckhwd	xmm4, xmm3
	punpcklwd	xmm5, xmm3
	movdqa		xmm0, [c1]
	pmaddwd		xmm4, xmm0
	pmaddwd		xmm5, xmm0

	; b = y + cb * 1.177
	; implemented as
	; y * scale + cb * 1.777 
	movdqa		xmm6, xmm1
	movdqa		xmm7, xmm1
	punpckhwd	xmm6, xmm2
	punpcklwd	xmm7, xmm2
	movdqa		xmm0, [c3]
	pmaddwd		xmm6, xmm0
	pmaddwd		xmm7, xmm0

	; g = y + cb * -0.344 + cr * -0.714
	; implemented as
	; temp = cb * -0.344 + cr * -0.714
	; temp = temp + y
	movdqa		xmm8, xmm2
	movdqa		xmm9, xmm2
	punpckhwd	xmm8, xmm3
	punpcklwd	xmm9, xmm3
	movdqa		xmm0, [c2]
	pmaddwd		xmm8, xmm0
	pmaddwd		xmm9, xmm0
	
	movdqa		xmm0, [c4]

	; g
	paddd		xmm8, xmm0
	paddd		xmm9, xmm0
	psrad		xmm8, 12
	psrad		xmm9, 12
	packssdw	xmm9, xmm8
	paddw		xmm9, xmm1
	movdqa		xmm2, xmm9
	
	; r
	paddd		xmm4, xmm0
	paddd		xmm5, xmm0
	psrad		xmm4, 12
	psrad		xmm5, 12
	packssdw	xmm5, xmm4
	movdqa		xmm1, xmm5
	
	; b
	paddd		xmm6, xmm0
	paddd		xmm7, xmm0
	psrad		xmm6, 12
	psrad		xmm7, 12
	packssdw	xmm7, xmm6
	movdqa		xmm3, xmm7
	
	packuswb	xmm1, xmm1
	packuswb	xmm2, xmm2
	packuswb	xmm3, xmm3

.setpels:
	sub			rsp, 8
	movq		[rsp], xmm1
	rept 4 counter:0 {
		mov			al, byte[rsp+(counter*2)+0]
		mov			cl, byte[rsp+(counter*2)+1]
		
		mov			byte[rcx+((counter*2)+0)*3+0], al
		mov			byte[rcx+((counter*2)+1)*3+0], cl
	}

	movq		[rsp], xmm2
	rept 4 counter:0 {
		mov			al, byte[rsp+(counter*2)+0]
		mov			cl, byte[rsp+(counter*2)+1]
		
		mov			byte[rcx+((counter*2)+0)*3+0], al
		mov			byte[rcx+((counter*2)+1)*3+0], cl
	}

	movq		[rsp], xmm3
	rept 4 counter:0 {
		mov			al, byte[rsp+(counter*2)+0]
		mov			cl, byte[rsp+(counter*2)+1]
		
		mov			byte[rcx+((counter*2)+0)*3+0], al
		mov			byte[rcx+((counter*2)+1)*3+0], cl
	}

	add			rsp, 8
	ret

.notransform:
	movdqa		xmm0, [c128]
	paddw		xmm1, xmm0
	paddw		xmm2, xmm0
	paddw		xmm3, xmm0
	packuswb	xmm1, xmm1
	packuswb	xmm2, xmm2
	packuswb	xmm3, xmm3

	jmp near .setpels


; Constants
C6xSQRT2 equ  4433
S6xSQRT2 equ 10703
A equ   2446
B equ  16819
C equ  25172
D equ  12299
E equ  -7373
F equ -20995
G equ -16069
H equ  -3196
I equ   9633

align 16
rotation1a: dw 4 dup ( S6xSQRT2, C6xSQRT2)
rotation1b: dw 4 dup (-C6xSQRT2, S6xSQRT2)

cI_IsumG: dw 4 dup (I+G, I)
cIsumH_I: dw 4 dup (I, I+H)

cE_DsumE: dw 4 dup (D+E, E)
cAsumE_E: dw 4 dup (E, A+E)

cF_CsumF: dw 4 dup (C+F, F)
cBsumF_F: dw 4 dup (F, B+F)

bias1:
	dd 4 dup (2048)
bias2:
	dd 4 dup (65536)


; rdi=sblock, rsi=rblock, rdx=qtable
jpgr_inverseDCT:
	mov 		rax, rsp
	sub			rsp, 98h

	; even part
	movdqa		xmm0, [rdi+20h]
	movdqa		xmm1, [rdi+60h]
	pmullw		xmm0, [rdx+20h]  ; xmm0=row2
	pmullw		xmm1, [rdx+60h]  ; xmm1=row6

	; rotation 1:
	; temp1 = row2 * -(C6xSQRT2) + row6 * (S6xSQRT2)
	; temp2 = row2 *  (S6xSQRT2) + row6 * (C6xSQRT2)
	movdqa		xmm2, xmm0
	punpcklwd	xmm0, xmm1
	punpckhwd	xmm2, xmm1

	movdqa		xmm1, xmm0
	movdqa		xmm3, xmm2
	pmaddwd		xmm1, [rotation1b]  ; xmm1=temp1lo
	pmaddwd		xmm3, [rotation1b]  ; xmm3=temp1hi
	pmaddwd		xmm0, [rotation1a]  ; xmm0=temp2lo
	pmaddwd		xmm2, [rotation1a]  ; xmm2=temp2hi

	; dirty: xmm0 xmm1 xmm2 xmm3
	; load row0 and row4
	movdqa		xmm4, [rdi+ 0h]
	movdqa		xmm5, [rdi+40h]
	pmullw		xmm4, [rdx+ 0h]  ; xmm4=row0
	pmullw		xmm5, [rdx+40h]  ; xmm5=row4

	; temp3 = (row0 + row4) << 13
	; temp4 = (row0 - row4) << 13
	movdqa		xmm6, xmm4
	paddw		xmm4, xmm5
	psubw		xmm6, xmm5
	pxor		xmm7, xmm7
	pxor		xmm5, xmm5
	punpcklwd	xmm7, xmm4  ; xmm7=temp3lo
	punpckhwd	xmm5, xmm4  ; xmm5=temp3hi
	psrad		xmm7, 3
	psrad		xmm5, 3

	pxor		xmm4, xmm4
	pxor		xmm8, xmm8
	punpcklwd	xmm4, xmm6  ; xmm4=temp4lo
	punpckhwd	xmm8, xmm6  ; xmm8=temp4hi
	psrad		xmm4, 3
	psrad		xmm8, 3

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm4 xmm5 xmm7 xmm8
	; stage 2 
	; lane0 = temp2 + temp3
	; lane3 = temp3 - temp2
	; lane1 = temp4 - temp1
	; lane2 = temp1 + temp4

	; preserve temp2
	movdqa		xmm6, xmm0
	movdqa		xmm9, xmm2
	paddd		xmm0, xmm7  ; xmm0=lane0lo
	paddd		xmm2, xmm5  ; xmm2=lane0hi
	psubd		xmm7, xmm6  ; xmm7=lane3lo
	psubd		xmm5, xmm9  ; xmm5=lane3hi

	; push lane 0 on the stack
	movaps		[rsp+ 0h], xmm0
	movaps		[rsp+10h], xmm2

	; preserve temp4
	movdqa		xmm6, xmm4
	movdqa		xmm9, xmm8
	psubd		xmm4, xmm1  ; xmm4=lane1lo
	psubd		xmm8, xmm3  ; xmm8=lane1hi

	; push lane 3 on the stack
	movaps		[rsp+60h], xmm7
	movaps		[rsp+70h], xmm5
	paddd		xmm1, xmm6  ; xmm1=lane2lo
	paddd		xmm3, xmm9  ; xmm3=lane2hi

	; push lane 1 and 2 on the stack
	movaps		[rsp+20h], xmm4
	movaps		[rsp+30h], xmm8
	movaps		[rsp+40h], xmm1
	movaps		[rsp+50h], xmm3

	; odd part
	; load row7 row5 row3 and row1
	movdqa		xmm0, [rdi+70h]
	movdqa		xmm1, [rdi+50h]
	pmullw		xmm0, [rdx+70h]  ; xmm0=row7
	pmullw		xmm1, [rdx+50h]  ; xmm1=row5
	movdqa		xmm2, [rdi+30h]
	movdqa		xmm3, [rdi+10h]
	pmullw		xmm2, [rdx+30h]  ; xmm2=row3
	pmullw		xmm3, [rdx+10h]  ; xmm3=row1

	; dirty: xmm0 xmm1 xmm2 xmm3

	; original:
	; z5 = (z3 + z4) * I
	; z3 = z3 * G
	; z4 = z4 * H
	; z3 += z5
	; z4 += z5
	;
	; this implementation:
	; z3 = z3 * (I    ) + z4 * (I + G)
	; z4 = z3 * (I + H) + z4 * (I)
	movdqa		xmm4, xmm0
	movdqa		xmm5, xmm1
	paddw		xmm4, xmm2  ; z3=row7+row3
	paddw		xmm5, xmm3  ; z4=row5+row1
	movdqa		xmm6, xmm4
	punpcklwd	xmm4, xmm5
	punpckhwd	xmm6, xmm5

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm4 xmm6
	movdqa		xmm5, xmm4
	movdqa		xmm7, xmm6
	pmaddwd		xmm5, [cI_IsumG]  ; xmm5=z3lo
	pmaddwd		xmm7, [cI_IsumG]  ; xmm7=z3hi
	pmaddwd		xmm4, [cIsumH_I]  ; xmm4=z4lo
	pmaddwd		xmm6, [cIsumH_I]  ; xmm6=z4hi

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm4 xmm5 xmm6 xmm7

	; (row1 * D) + ((row7 + row1) * E)
	; (row7 * A) + ((row7 + row1) * E)
	; (row3 * C) + ((row5 + row3) * F)
	; (row5 * B) + ((row5 + row3) * F)
	;
	; then:
	; x * (a + b) + y * b
	movdqa		xmm9, xmm3  ; preserve row1
	punpcklwd	xmm3, xmm0
	punpckhwd	xmm9, xmm0
	
	; xmm0 is free now
	movdqa		xmm0, xmm3 
	movdqa		xmm8, xmm9 
	pmaddwd		xmm0, [cE_DsumE]  ; xmm0=lane7lo
	pmaddwd		xmm8, [cE_DsumE]  ; xmm8=lane7hi

	pmaddwd		xmm3, [cAsumE_E]  ; xmm3=lane4lo
	pmaddwd		xmm9, [cAsumE_E]  ; xmm9=lane4hi

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm4 xmm5 xmm6 xmm7 xmm8 xmm9
	movdqa		xmmA, xmm2  ; preserve row3
	punpcklwd	xmm2, xmm1
	punpckhwd	xmmA, xmm1

	; xmm1 is free now
	movdqa		xmm1, xmm2
	movdqa		xmmB, xmmA
	pmaddwd		xmm1, [cF_CsumF]  ; xmm1=lane6lo
	pmaddwd		xmmB, [cF_CsumF]  ; xmmB=lane6hi
	pmaddwd		xmm2, [cBsumF_F]  ; xmm2=lane5lo
	pmaddwd		xmmA, [cBsumF_F]  ; xmmA=lane5hi

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm4 xmm5 xmm6 xmm7 xmm8 xmm9 xmmA xmmB
	; lane7 += z4
	; lane5 += z4
	; lane4 += z3
	; lane6 += z3
	paddd		xmm0, xmm4  ; xmm0=lane7lo
	paddd		xmm8, xmm6  ; xmm8=lane7hi
	paddd		xmm2, xmm4  ; xmm2=lane5lo
	paddd		xmmA, xmm6  ; xmmA=lane5hi

	paddd		xmm3, xmm5  ; xmm3=lane4lo
	paddd		xmm9, xmm7  ; xmm9=lane4hi
	paddd		xmm1, xmm5  ; xmm1=lane6lo
	paddd		xmmB, xmm7  ; xmmB=lane6hi

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm8 xmm9 xmmA xmmB
	
	movdqa		xmm4, [bias1]

	; last stage
	; row0 = ((lane0 + lane7) + 2048) >> 12
	; row7 = ((lane0 - lane7) + 2048) >> 12
	; row1 = ((lane1 + lane6) + 2048) >> 12
	; row6 = ((lane1 - lane6) + 2048) >> 12
	; row2 = ((lane2 + lane5) + 2048) >> 12
	; row5 = ((lane2 - lane5) + 2048) >> 12
	; row3 = ((lane3 + lane4) + 2048) >> 12
	; row4 = ((lane3 - lane4) + 2048) >> 12

	movaps		xmm5, [rsp+ 0h]
	movaps		xmm6, [rsp+10h]
	paddd		xmm5, xmm0
	paddd		xmm6, xmm8
	paddd		xmm5, xmm4
	paddd		xmm6, xmm4
	psrad		xmm5, 12
	psrad		xmm6, 12
	packssdw	xmm5, xmm6  ; xmm5=row0
	; xmm6 is free now

	movaps		xmm6, [rsp+ 0h]
	movaps		xmm7, [rsp+10h]
	psubd		xmm6, xmm0
	psubd		xmm7, xmm8
	paddd		xmm6, xmm4
	paddd		xmm7, xmm4
	psrad		xmm6, 12
	psrad		xmm7, 12
	packssdw	xmm6, xmm7  ; xmm6=row7

	; dirty: xmm1 xmm2 xmm3 xmm4 xmm5 xmm6 xmm9 xmmA xmmB
	movaps		xmm8, [rsp+20h]
	movaps		xmm0, [rsp+30h]
	paddd		xmm8, xmm1
	paddd		xmm0, xmmB
	paddd		xmm8, xmm4
	paddd		xmm0, xmm4
	psrad		xmm8, 12
	psrad		xmm0, 12
	packssdw	xmm8, xmm0  ; xmm8=row1

	movaps		xmm0, [rsp+20h]
	movaps		xmmC, [rsp+30h]
	psubd		xmm0, xmm1
	psubd		xmmC, xmmB
	paddd		xmm0, xmm4
	paddd		xmmC, xmm4
	psrad		xmm0, 12
	psrad		xmmC, 12
	packssdw	xmm0, xmmC  ; xmm0=row6

	; dirty: xmm0 xmm2 xmm3 xmm4 xmm5 xmm6 xmm8 xmm9 xmmA
	movaps		xmm1, [rsp+40h]
	movaps		xmmB, [rsp+50h]
	paddd		xmm1, xmm2
	paddd		xmmB, xmmA
	paddd		xmm1, xmm4
	paddd		xmmB, xmm4
	psrad		xmm1, 12
	psrad		xmmB, 12
	packssdw	xmm1, xmmB  ; xmm1=row2

	movaps		xmmB, [rsp+40h]
	movaps		xmmC, [rsp+50h]
	psubd		xmmB, xmm2
	psubd		xmmC, xmmA
	paddd		xmmB, xmm4
	paddd		xmmC, xmm4
	psrad		xmmB, 12
	psrad		xmmC, 12
	packssdw	xmmB, xmmC  ; xmmB=row5

	; dirty: xmm0 xmm1 xmm3 xmm4 xmm5 xmm6 xmm8 xmm9 xmmB
	movaps		xmmC, [rsp+60h]
	movaps		xmmD, [rsp+70h]
	paddd		xmmC, xmm3
	paddd		xmmD, xmm9
	paddd		xmmC, xmm4
	paddd		xmmD, xmm4
	psrad		xmmC, 12
	psrad		xmmD, 12
	packssdw	xmmC, xmmD  ; xmmC=row3

	movaps		xmmD, [rsp+60h]
	movaps		xmmE, [rsp+70h]
	psubd		xmmD, xmm3
	psubd		xmmE, xmm9
	paddd		xmmD, xmm4
	paddd		xmmE, xmm4
	psrad		xmmD, 12
	psrad		xmmE, 12
	packssdw	xmmD, xmmE  ; xmmD=row4

	; dirty: xmm0 xmm1 xmm5 xmm6 xmm8 xmmB xmmC xmmD

	; row0=xmm5
	; row1=xmm8
	; row2=xmm1
	; row3=xmmC
	; row4=xmmD
	; row5=xmmB
	; row6=xmm0
	; row7=xmm6

	; transpose row columns
	movdqa		xmm2, xmm5
	punpcklwd	xmm5, xmmD
	punpckhwd	xmm2, xmmD  ; xmm2=row4

	movdqa		xmm3, xmm8
	punpcklwd	xmm8, xmmB
	punpckhwd	xmm3, xmmB  ; xmm3=row5

	movdqa		xmm4, xmm1
	punpcklwd	xmm1, xmm0
	punpckhwd	xmm4, xmm0	; xmm4=row6

	movdqa		xmm7, xmmC
	punpcklwd	xmmC, xmm6
	punpckhwd	xmm7, xmm6  ; xmm7=row7

	; row0=xmm5
	; row1=xmm8
	; row2=xmm1
	; row3=xmmC
	; row4=xmm2
	; row5=xmm3
	; row6=xmm4
	; row7=xmm7

	; dirty: xmm1 xmm2 xmm3 xmm4 xmm5 xmm7 xmm8 xmmC
	movdqa		xmm0, xmm5
	punpcklwd	xmm5, xmm1
	punpckhwd	xmm0, xmm1  ; xmm0=row2

	movdqa		xmm1, xmm8
	punpcklwd	xmm8, xmmC
	punpckhwd	xmm1, xmmC  ; xmm1=row3

	movdqa		xmm6, xmm2
	punpcklwd	xmm2, xmm4
	punpckhwd	xmm6, xmm4  ; xmm6=row6

	movdqa		xmm4, xmm3
	punpcklwd	xmm3, xmm7
	punpckhwd	xmm4, xmm7  ; xmm4=row7

	; row0=xmm5
	; row1=xmm8
	; row2=xmm0
	; row3=xmm1
	; row4=xmm2
	; row5=xmm3
	; row6=xmm6
	; row7=xmm4

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm4 xmm5 xmm6 xmm8
	movdqa		xmm7, xmm5
	punpcklwd	xmm5, xmm8
	punpckhwd	xmm7, xmm8  ; xmm7=row1

	movdqa		xmm8, xmm0
	punpcklwd	xmm0, xmm1
	punpckhwd	xmm8, xmm1  ; xmm8=row3

	movdqa		xmm1, xmm2
	punpcklwd	xmm2, xmm3
	punpckhwd	xmm1, xmm3  ; xmm1=row5

	movdqa		xmm3, xmm6
	punpcklwd	xmm6, xmm4
	punpckhwd	xmm3, xmm4  ; xmm3=row7

	; row0=xmm5
	; row1=xmm7
	; row2=xmm0
	; row3=xmm8
	; row4=xmm2
	; row5=xmm1
	; row6=xmm6
	; row7=xmm3

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm5 xmm6 xmm8

	; rearrange rows
	movdqa		xmmB, xmm7  ; row1
	movdqa		xmmC, xmm8  ; row3
	movdqa		xmmD, xmm1  ; row5
	movdqa		xmmE, xmm3  ; row7

	movdqa		xmm7, xmm5  ; row0
	movdqa		xmm8, xmm2  ; row4

	; row2=xmm0
	movdqa		xmm1, xmm6

	; second pass

	; rotation 1:
	; temp1 = row2 * -(C6xSQRT2) + row6 * (S6xSQRT2)
	; temp2 = row2 *  (S6xSQRT2) + row6 * (C6xSQRT2)
	movdqa		xmm2, xmm0
	punpcklwd	xmm0, xmm1
	punpckhwd	xmm2, xmm1

	movdqa		xmm1, xmm0
	movdqa		xmm3, xmm2
	pmaddwd		xmm1, [rotation1b]  ; xmm1=temp1lo
	pmaddwd		xmm3, [rotation1b]  ; xmm3=temp1hi
	pmaddwd		xmm0, [rotation1a]  ; xmm0=temp2lo
	pmaddwd		xmm2, [rotation1a]  ; xmm2=temp2hi

	; dirty: xmm0 xmm1 xmm2 xmm3
	; load row0 and row4
	movdqa		xmm4, xmm7
	movdqa		xmm5, xmm8

	; temp3 = (row0 + row4) << 13
	; temp4 = (row0 - row4) << 13
	movdqa		xmm6, xmm4
	paddw		xmm4, xmm5
	psubw		xmm6, xmm5
	pxor		xmm7, xmm7
	pxor		xmm5, xmm5
	punpcklwd	xmm7, xmm4  ; xmm7=temp3lo
	punpckhwd	xmm5, xmm4  ; xmm5=temp3hi
	psrad		xmm7, 3
	psrad		xmm5, 3

	pxor		xmm4, xmm4
	pxor		xmm8, xmm8
	punpcklwd	xmm4, xmm6  ; xmm4=temp4lo
	punpckhwd	xmm8, xmm6  ; xmm8=temp4hi
	psrad		xmm4, 3
	psrad		xmm8, 3

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm4 xmm5 xmm7 xmm8
	; stage 2 
	; lane0 = temp2 + temp3
	; lane3 = temp3 - temp2
	; lane1 = temp4 - temp1
	; lane2 = temp1 + temp4

	; preserve temp2
	movdqa		xmm6, xmm0
	movdqa		xmm9, xmm2
	paddd		xmm0, xmm7  ; xmm0=lane0lo
	paddd		xmm2, xmm5  ; xmm2=lane0hi
	psubd		xmm7, xmm6  ; xmm7=lane3lo
	psubd		xmm5, xmm9  ; xmm5=lane3hi

	; push lane 0 the stack
	movaps		[rsp+ 0h], xmm0
	movaps		[rsp+10h], xmm2

	; preserve temp4
	movdqa		xmm6, xmm4
	movdqa		xmm9, xmm8
	psubd		xmm4, xmm1  ; xmm4=lane1lo
	psubd		xmm8, xmm3  ; xmm8=lane1hi

	; push lane 3 the stack
	movaps		[rsp+60h], xmm7
	movaps		[rsp+70h], xmm5
	paddd		xmm1, xmm6  ; xmm1=lane2lo
	paddd		xmm3, xmm9  ; xmm3=lane2hi

	; push lane 1 and 2 the stack
	movaps		[rsp+20h], xmm4
	movaps		[rsp+30h], xmm8
	movaps		[rsp+40h], xmm1
	movaps		[rsp+50h], xmm3

	; odd part
	; load row7 row5 row3 and row1
	movdqa		xmm0, xmmE
	movdqa		xmm1, xmmD
	movdqa		xmm2, xmmC
	movdqa		xmm3, xmmB

	; dirty: xmm0 xmm1 xmm2 xmm3
	; original:
	; z5 = (z3 + z4) * I
	; z3 = z3 * G
	; z4 = z4 * H
	; z3 += z5
	; z4 += z5
	;
	; this implementation:
	; z3 = z3 * (I    ) + z4 * (I + G)
	; z4 = z3 * (I + H) + z4 * (I)
	movdqa		xmm4, xmm0
	movdqa		xmm5, xmm1
	paddw		xmm4, xmm2  ; z3=row7+row3
	paddw		xmm5, xmm3  ; z4=row5+row1
	movdqa		xmm6, xmm4
	punpcklwd	xmm4, xmm5
	punpckhwd	xmm6, xmm5

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm4 xmm6
	movdqa		xmm5, xmm4
	movdqa		xmm7, xmm6
	pmaddwd		xmm5, [cI_IsumG]  ; xmm5=z3lo
	pmaddwd		xmm7, [cI_IsumG]  ; xmm7=z3hi
	pmaddwd		xmm4, [cIsumH_I]  ; xmm4=z4lo
	pmaddwd		xmm6, [cIsumH_I]  ; xmm6=z4hi

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm4 xmm5 xmm6 xmm7

	; (row1 * D) + ((row7 + row1) * E)
	; (row7 * A) + ((row7 + row1) * E)
	; (row3 * C) + ((row5 + row3) * F)
	; (row5 * B) + ((row5 + row3) * F)
	;
	; then:
	; x * (a + b) + y * b
	movdqa		xmm9, xmm3  ; preserve row1
	punpcklwd	xmm3, xmm0
	punpckhwd	xmm9, xmm0
	
	; xmm0 is free now
	movdqa		xmm0, xmm3
	movdqa		xmm8, xmm9
	pmaddwd		xmm0, [cE_DsumE]  ; xmm0=lane7lo
	pmaddwd		xmm8, [cE_DsumE]  ; xmm8=lane7hi

	pmaddwd		xmm3, [cAsumE_E]  ; xmm3=lane4lo
	pmaddwd		xmm9, [cAsumE_E]  ; xmm9=lane4hi

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm4 xmm5 xmm6 xmm7 xmm8 xmm9
	movdqa		xmmA, xmm2  ; preserve row3
	punpcklwd	xmm2, xmm1
	punpckhwd	xmmA, xmm1

	; xmm1 is free now
	movdqa		xmm1, xmm2
	movdqa		xmmB, xmmA
	pmaddwd		xmm1, [cF_CsumF]  ; xmm1=lane6lo
	pmaddwd		xmmB, [cF_CsumF]  ; xmmB=lane6hi
	pmaddwd		xmm2, [cBsumF_F]  ; xmm2=lane5lo
	pmaddwd		xmmA, [cBsumF_F]  ; xmmA=lane5hi

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm4 xmm5 xmm6 xmm7 xmm8 xmm9 xmmA xmmB
	; lane7 += z4
	; lane5 += z4
	; lane4 += z3
	; lane6 += z3
	paddd		xmm0, xmm4  ; xmm0=lane7lo
	paddd		xmm8, xmm6  ; xmm8=lane7hi
	paddd		xmm2, xmm4  ; xmm2=lane5lo
	paddd		xmmA, xmm6  ; xmmA=lane5hi

	paddd		xmm3, xmm5  ; xmm3=lane4lo
	paddd		xmm9, xmm7  ; xmm9=lane4hi
	paddd		xmm1, xmm5  ; xmm1=lane6lo
	paddd		xmmB, xmm7  ; xmmB=lane6hi

	; dirty: xmm0 xmm1 xmm2 xmm3 xmm8 xmm9 xmmA xmmB
	
	movdqa		xmm4, [bias2]

	; last stage
	; row0 = ((lane0 + lane7) + 65536) >> 17
	; row7 = ((lane0 - lane7) + 65536) >> 17
	; row1 = ((lane1 + lane6) + 65536) >> 17
	; row6 = ((lane1 - lane6) + 65536) >> 17
	; row2 = ((lane2 + lane5) + 65536) >> 17
	; row5 = ((lane2 - lane5) + 65536) >> 17
	; row3 = ((lane3 + lane4) + 65536) >> 17
	; row4 = ((lane3 - lane4) + 65536) >> 17
	movdqa		xmm5, [rsp+ 0h]
	movdqa		xmm6, [rsp+10h]
	paddd		xmm5, xmm0
	paddd		xmm6, xmm8
	paddd		xmm5, xmm4
	paddd		xmm6, xmm4
	psrad		xmm5, 17
	psrad		xmm6, 17
	packssdw	xmm5, xmm6  ; xmm5=row0
	; xmm6 is free now

	movdqa		xmm6, [rsp+ 0h]
	movdqa		xmm7, [rsp+10h]
	psubd		xmm6, xmm0
	psubd		xmm7, xmm8
	movaps		[rsi+ 0h], xmm5
	paddd		xmm6, xmm4
	paddd		xmm7, xmm4
	psrad		xmm6, 17
	psrad		xmm7, 17
	packssdw	xmm6, xmm7  ; xmm6=row7

	; dirty: xmm1 xmm2 xmm3 xmm4 xmm5 xmm6 xmm9 xmmA xmmB
	movdqa		xmm8, [rsp+20h]
	movdqa		xmm0, [rsp+30h]
	paddd		xmm8, xmm1
	paddd		xmm0, xmmB
	movaps		[rsi+70h], xmm6
	paddd		xmm8, xmm4
	paddd		xmm0, xmm4
	psrad		xmm8, 17
	psrad		xmm0, 17
	packssdw	xmm8, xmm0  ; xmm8=row1

	movdqa		xmm0, [rsp+20h]
	movdqa		xmmC, [rsp+30h]
	psubd		xmm0, xmm1
	psubd		xmmC, xmmB
	movaps		[rsi+10h], xmm8
	paddd		xmm0, xmm4
	paddd		xmmC, xmm4
	psrad		xmm0, 17
	psrad		xmmC, 17
	packssdw	xmm0, xmmC  ; xmm0=row6

	; dirty: xmm0 xmm2 xmm3 xmm4 xmm5 xmm6 xmm8 xmm9 xmmA
	movdqa		xmm1, [rsp+40h]
	movdqa		xmmB, [rsp+50h]
	paddd		xmm1, xmm2
	paddd		xmmB, xmmA
	movaps		[rsi+60h], xmm0
	paddd		xmm1, xmm4
	paddd		xmmB, xmm4
	psrad		xmm1, 17
	psrad		xmmB, 17
	packssdw	xmm1, xmmB  ; xmm1=row2

	movdqa		xmmB, [rsp+40h]
	movdqa		xmmC, [rsp+50h]
	psubd		xmmB, xmm2
	psubd		xmmC, xmmA
	movaps		[rsi+20h], xmm1
	paddd		xmmB, xmm4
	paddd		xmmC, xmm4
	psrad		xmmB, 17
	psrad		xmmC, 17
	packssdw	xmmB, xmmC  ; xmmB=row5

	; dirty: xmm0 xmm1 xmm3 xmm4 xmm5 xmm6 xmm8 xmm9 xmmB
	movdqa		xmmC, [rsp+60h]
	movdqa		xmmD, [rsp+70h]
	paddd		xmmC, xmm3
	paddd		xmmD, xmm9
	movaps		[rsi+50h], xmmB
	paddd		xmmC, xmm4
	paddd		xmmD, xmm4
	psrad		xmmC, 17
	psrad		xmmD, 17
	packssdw	xmmC, xmmD  ; xmmC=row3

	movdqa		xmmD, [rsp+60h]
	movdqa		xmmE, [rsp+70h]
	psubd		xmmD, xmm3
	psubd		xmmE, xmm9
	movaps		[rsi+30h], xmmC
	paddd		xmmD, xmm4
	paddd		xmmE, xmm4
	psrad		xmmD, 17
	psrad		xmmE, 17
	packssdw	xmmD, xmmE  ; xmmD=row4
	movaps		[rsi+40h], xmmD
	
	mov 		rsp, rax
	ret


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; SSSE3 version
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

; Suffle tables
align 16
suffle1:
	.1: db  0, -1, -1,  1, -1, -1,  2, -1, -1,  3, -1, -1,  4, -1, -1,  5
	.2: db -1, -1,  6, -1, -1,  7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

suffle2:
	.1: db -1,  0, -1, -1,  1, -1, -1,  2, -1, -1,  3, -1, -1,  4, -1, -1
	.2: db  5, -1, -1,  6, -1, -1,  7, -1, -1, -1, -1, -1, -1, -1, -1, -1

suffle3:
	.1: db -1, -1,  0, -1, -1,  1, -1, -1,  2, -1, -1,  3, -1, -1,  4, -1
	.2: db -1,  5, -1, -1,  6, -1, -1,  7, -1, -1, -1, -1, -1, -1, -1, -1

; rdi=r1, rsi=r2, rdx=r3, rcx=destination, r8=transform
ssse3_setrow3:
	movdqa      xmm1, [rdi]
	movdqa      xmm2, [rsi]
	movdqa      xmm3, [rdx]

	cmp			r8, 0h
	je .notransform

	; r = y + cr * 1.402
	; implemented as 
	; y * scale + cr * 1.402
	movdqa		xmm4, xmm1
	movdqa		xmm5, xmm1
	punpckhwd	xmm4, xmm3
	punpcklwd	xmm5, xmm3
	movdqa		xmm0, [c1]
	pmaddwd		xmm4, xmm0
	pmaddwd		xmm5, xmm0

	; b = y + cb * 1.177
	; implemented as
	; y * scale + cb * 1.777 
	movdqa		xmm6, xmm1
	movdqa		xmm7, xmm1
	punpckhwd	xmm6, xmm2
	punpcklwd	xmm7, xmm2
	movdqa		xmm0, [c3]
	pmaddwd		xmm6, xmm0
	pmaddwd		xmm7, xmm0

	; g = y + cb * -0.344 + cr * -0.714
	; implemented as
	; temp = cb * -0.344 + cr * -0.714
	; temp = temp + y
	movdqa		xmm8, xmm2
	movdqa		xmm9, xmm2
	punpckhwd	xmm8, xmm3
	punpcklwd	xmm9, xmm3
	movdqa		xmm0, [c2]
	pmaddwd		xmm8, xmm0
	pmaddwd		xmm9, xmm0
	
	movdqa		xmm0, [c4]

	; g
	paddd		xmm8, xmm0
	paddd		xmm9, xmm0
	psrad		xmm8, 12
	psrad		xmm9, 12
	packssdw	xmm9, xmm8
	paddw		xmm9, xmm1
	movdqa		xmm2, xmm9
	
	; r
	paddd		xmm4, xmm0
	paddd		xmm5, xmm0
	psrad		xmm4, 12
	psrad		xmm5, 12
	packssdw	xmm5, xmm4
	movdqa		xmm1, xmm5
	
	; b
	paddd		xmm6, xmm0
	paddd		xmm7, xmm0
	psrad		xmm6, 12
	psrad		xmm7, 12
	packssdw	xmm7, xmm6
	movdqa		xmm3, xmm7
	
	packuswb	xmm1, xmm1
	packuswb	xmm2, xmm2
	packuswb	xmm3, xmm3

.setpels:
	; ssse3 ssufle_epi8
	movdqa		xmm0, [suffle1.1]
	movdqa		xmm4, xmm1
	pshufb		xmm4, xmm0
	
	movdqa		xmm0, [suffle2.1]
	movdqa		xmm5, xmm2
	pshufb		xmm5, xmm0
	
	movdqa		xmm0, [suffle3.1]
	movdqa		xmm6, xmm3
	pshufb		xmm6, xmm0
	
	por			xmm6, xmm5
	por			xmm6, xmm4
	movdqu		[rcx], xmm6
	
	; remaning pixels
	movdqa		xmm0, [suffle1.2]
	movdqa		xmm4, xmm1
	pshufb		xmm4, xmm0
	
	movdqa		xmm0, [suffle2.2]
	movdqa		xmm5, xmm2
	pshufb		xmm5, xmm0
	
	movdqa		xmm0, [suffle3.2]
	movdqa		xmm6, xmm3
	pshufb		xmm6, xmm0
	
	por			xmm6, xmm5
	por			xmm6, xmm4
	movq		[rcx+10h], xmm6

	ret
	
.notransform:
	movdqa		xmm0, [c128]
	paddw		xmm1, xmm0
	paddw		xmm2, xmm0
	paddw		xmm3, xmm0
	packuswb	xmm1, xmm1
	packuswb	xmm2, xmm2
	packuswb	xmm3, xmm3

	jmp near .setpels


section '.data' align 16

jumptable:
	.setrow3:
		dq initjump

initdone:
	dq 0h
